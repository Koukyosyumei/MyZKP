\documentclass{article}


\usepackage{PRIMEarxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc
\usepackage{multicol}
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{fancyhdr}       % header
\usepackage{graphicx}       % graphics
\usepackage{listings}
\graphicspath{{media/}}     % organize your images and other figures under media/ folder

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{centernot}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{graphicx,wrapfig,lipsum}
\usepackage{color}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{bm}

\lstset{
 	language = C++,
        backgroundcolor={\color[gray]{.90}},
}

\newcommand{\argmin}{\mathop{\rm arg~min}\limits}
\newcommand{\argmax}{\mathop{\rm arg~max}\limits}

\newcommand{\hideaki}[1]{\textcolor{olive}{\small{\bf [Hideaki: #1 ]}}}

\tcbuselibrary{theorems}
\newtcbtheorem
  []% init options
  {definition}% name
  {Definition}% title
  {%
    colback=green!5,
    colframe=green!35!black,
    fonttitle=\bfseries,
  }% options
  {def}% prefix

\tcbuselibrary{theorems}
\newtcbtheorem
  []% init options
  {theorem}% name
  {Theorem}% title
  {%
    colback=blue!5,
    colframe=blue!35!black,
    fonttitle=\bfseries,
  }% options
  {thm}% prefix

\tcbuselibrary{theorems}
\newtcbtheorem
  []% init options
  {proposition}% name
  {Proposition}% title
  {%
    colback=blue!5,
    colframe=blue!35!black,
    fonttitle=\bfseries,
  }% options
  {prop}% prefix

\tcbuselibrary{theorems}
\newtcbtheorem
  []% init options
  {lemma}% name
  {Lemma}% title
  {%
    colback=blue!5,
    colframe=blue!35!black,
    fonttitle=\bfseries,
  }% options
  {lem}% prefix

\tcbuselibrary{theorems}
\newtcbtheorem
  []% init options
  {assumption}% name
  {Assumption}% title
  {%
    colback=red!5,
    colframe=red!35!black,
    fonttitle=\bfseries,
  }% options
  {asm}% prefix

\tcbuselibrary{theorems}
\newtcbtheorem
  []% init options
  {protocol}% name
  {Protocol}% title
  {%
    colback=yellow!5,
    colframe=yellow!35!black,
    fonttitle=\bfseries,
  }% options
  {pro}% prefix

\tcbuselibrary{theorems}
\newtcbtheorem
  []% init options
  {corollary}% name
  {Corollary}% title
  {%
    colback=yellow!5,
    colframe=yellow!35!black,
    fonttitle=\bfseries,
  }% options
  {cor}% prefix
  

%Header
\pagestyle{fancy}
\thispagestyle{empty}
\rhead{ \textit{ }} 

% Update your Headers here
%\fancyhead[LO]{Running Title for Header}
% \fancyhead[RE]{Firstauthor and Secondauthor} % Firstauthor et al. if more than 2 - must use \documentclass[twoside]{article}



  
%% Title
\title{MyZKP: Introduction to Zero Knowledge Protocol
%%%% Cite as
%%%% Update your official citation here when published 
%\thanks{\textit{\underline{Citation}}: 
%\textbf{Authors. Title. Pages.... DOI:000000/11111.}} 
}

\author{
    Hideaki Takahashi \\
    Columbia University \\
    ht2673@columbia.edu
%  Affiliation \\
%  Univ \\
%  City\\
%  \texttt{\{Author1, Author2\}email@email} \\
  %% examples of more authors
%   \And
%  Author3 \\
%  Affiliation \\
%  Univ \\
%  City\\
%  \texttt{email@email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}


\begin{document}
\maketitle


%\begin{abstract}

%\end{abstract}

% keywords can be removed
%\keywords{Code Obfuscation \and Software Security}

%\begin{multicols}{2}

\textbf{\textcolor{red}{THIS MANUSCRIPT IS WIP. IT IS LIKELY TO CONTAIN MANY WRONG INFORMATION}}

\tableofcontents

\section{Basics of Number Theory}

Let $X$ be a set in this section.

\subsection{Computation Rule and Properties}

\begin{definition}{Binary Operation}{}
A mapping $\circ: X \times X \rightarrow X$ is a binary operation on $X$ if for any pair of elements $(x_1, x_2)$ in $X$, $x_1 \circ x_2$ is also in $X$.
\end{definition}

Example: Addition (+) on the set of integers is a binary operation. For example, $5 + 3 = 8$, and both $5, 3, 8$ are integers, staying within the set of integers.

\begin{definition}{Associative Property}{}
A binary operation $\circ$ is associative if $(a \circ b) \circ c = a \circ (b \circ c)$ for all $a, b, c \in X$.
\end{definition}

Example: Multiplication of real numbers is associative: $(2 \times 3) \times 4 = 2 \times (3 \times 4) = 24$. In a modular context, we also have addition modulo $n$ being associative. For example, for $n = 5$, $(2 + 3) \bmod 5 + 4 \bmod 5 = 2 + (3 \bmod 5 + 4) \bmod 5 = 4$.

\begin{definition}{Commutative Property}{}
A binary operation $\circ$ is commutative if $a \circ b = b \circ a$ for all $a, b \in X$.
\end{definition}

Example: Addition modulo $n$ is also commutative. For $n = 7$, $5 + 3 \bmod 7 = 3 + 5 \bmod 7 = 1$.

\subsection{Semigroup, Group, Ring}

\begin{definition}{Semigroup}{}
A pair $(H, \circ)$, where $H$ is a non-empty set and $\circ$ is an associative binary operation on $H$, is called a semigroup.
\end{definition}

Example: The set of positive integers under multiplication modulo $n$ forms a semigroup. For instance, with $n = 6$, the elements $\{1, 2, 3, 4, 5\}$ under multiplication modulo 6 form a semigroup, since multiplication modulo 6 is associative.

\begin{definition}{Abelian Semigroup}{}
A semigroup whose operation is commutative is called an abelian semigroup.
\end{definition}

Example: The set of natural numbers under addition modulo $n$ forms an abelian semigroup. For $n = 7$, addition modulo 7 is both associative and commutative, so it is an abelian semigroup.

\begin{definition}{Identity Element}{}
An element $e \in H$ is an identity element of $H$ if it satisfies $e \circ a = a \circ e = a$ for any $a \in H$.
\end{definition}

Example: 0 is the identity element for addition modulo $n$. For example, $0 + a \bmod 5 = a + 0 \bmod 5 = a$. Similarly, 1 is the identity element for multiplication modulo $n$. For example, $1 \times a \bmod 7 = a \times 1 \bmod 7 = a$.

\begin{definition}{Monoid}{}
A semigroup with an identity element is called a monoid.
\end{definition}

Example: The set of non-negative integers under addition modulo $n$ forms a monoid. For $n = 5$, the set $\{0, 1, 2, 3, 4\}$ under addition modulo 5 forms a monoid with 0 as the identity element.

\begin{definition}{Inverse}{}
For an element $a \in H$, an element $b \in H$ is an inverse of $a$ if $a \circ b = b \circ a = e$, where $e$ is the identity element.
\end{definition}

Example: In modulo $n$ arithmetic (addition), the inverse of an element exists if it can cancel itself out to yield the identity element. In the set of integers modulo 7, the inverse of 3 is 5, because $3 \times 5 \bmod 7 = 1$, where 1 is the identity element for multiplication.

\begin{definition}{Group}{}
A monoid in which every element has an inverse is called a group.
\end{definition}

Example: The set of integers modulo a prime $p$ under multiplication forms a group (Can you prove it?). For instance, in $\mathbb{Z}/5\mathbb{Z}$, every non-zero element $\{1 + 5\mathbb{Z}, 2 + 5\mathbb{Z}, 3 + 5\mathbb{Z}, 4 + 5\mathbb{Z}\}$ has an inverse, making it a group.

\begin{definition}{Order of a Group}{}
The order of a group is the number of elements in the group.
\end{definition}

Example: The group of integers modulo 4 under addition has order 4, because the set of elements is $\{0, 1, 2, 3\}$.

\begin{definition}{Ring}{}
A triple $(R, +, \cdot)$ is a ring if $(R, +)$ is an abelian group, $(R, \cdot)$ is a semigroup, and the distributive property holds: $x \cdot (y + z) = (x \cdot y) + (x \cdot z)$ and $(x + y) \cdot z = (x \cdot z) + (y \cdot z)$ for all $x, y, z \in R$.
\end{definition}

Example: The set of integers with usual addition and multiplication modulo $n$ forms a ring. For example, in $\mathbb{Z}/6\mathbb{Z}$, addition and multiplication modulo 6 form a ring.

\begin{definition}{Commutative Ring}{}
A ring is called a commutative ring if its multiplication operation is commutative.
\end{definition}

The set of real numbers under usual addition and multiplication forms a commutative ring.

\begin{definition}{Field}{}
A commutative ring with a multiplicative identity element where every non-zero element has a multiplicative inverse is called a field.
\end{definition}

The set of rational numbers under usual addition and multiplication forms a field.

\begin{definition}{Residue Class}{}
The residue class of $a$ modulo $m$, denoted as $a + m\mathbb{Z}$, is the set $\{b : b \equiv a \pmod{m}\}$.
\end{definition}

Example: For $m = 3$, the residue class of 2 is $2 + 3\mathbb{Z} = \{\ldots, -4, -1, 2, 5, 8, \ldots\}$.

\begin{definition}{Inverse of Residue Class}{}
We denote the set of all residue classes modulo $m$ as $\mathbb{Z} / m\mathbb{Z}$. We say that $a + m\mathbb{Z}$ is invertible in $\mathbb{Z} / m\mathbb{Z}$ if and only if there exists a solution for $ax \equiv 1 \pmod{m}$.
\end{definition}

\begin{theorem}{}{}
$a + m\mathbb{Z}$ is invertible in $\mathbb{Z} / m\mathbb{Z}$ if and only if $\gcd(a, m) = 1$.
\end{theorem}

\begin{proof}
    TBD
\end{proof}

Example: In $\mathbb{Z}/5\mathbb{Z}$, $3 + 5\mathbb{Z}$ is invertible because $\gcd(3, 5) = 1$ ($3\cdot2 \equiv 1 \bmod 5$). However, in $\mathbb{Z}/6\mathbb{Z}$, $3 + 6\mathbb{Z}$ is not invertible because $\gcd(3, 6) = 3 \neq 1$ ($3 \cdot 1 \equiv 3 \bmod 6$, $3 \cdot 2 \equiv 0 \bmod 6$, $3 \cdot 3 \equiv 9 \bmod 6$, $3 \cdot 4 \equiv 0 \bmod 6$ ...).

\begin{definition}{Residue Class Ring}{}
$(\mathbb{Z} / m \mathbb{Z}, +, \cdot)$ is a commutative ring where $1 + m \mathbb{Z}$ is the multiplicative identity element. This ring is called the residue class ring modulo $m$.
\end{definition}

$\mathbb{Z}/4\mathbb{Z} = \{0 + 4\mathbb{Z}, 1 + 4\mathbb{Z}, 2 + 4\mathbb{Z}, 3 + 4\mathbb{Z}\}$ is a residue class ring modulo 4. We omit 

\begin{definition}{Primitive Residue Class}{}
A residue class $a + m\mathbb{Z}$ is called primitive if $\gcd(a, m) = 1$.
\end{definition}

Example: In $\mathbb{Z}/6\mathbb{Z}$, the primitive residue classes are $1 + 6\mathbb{Z}$ and $5 + 6\mathbb{Z}$.

\begin{theorem}{}{}
A residue ring $\mathbb{Z} / m\mathbb{Z}$ is a field if and only if $m$ is a prime number.
\end{theorem}

\begin{proof}
    TBD
\end{proof}

Example: For $m = 5$, $\mathbb{Z}/5\mathbb{Z} = \{0 + 5\mathbb{Z}, 1 + 5\mathbb{Z}, 2 + 5\mathbb{Z}, 3 + 5\mathbb{Z}, 4 + 5\mathbb{Z}\}$ forms a field because 5 is a prime number, and every non-zero element has a multiplicative inverse. For example, $3 \times 2 \bmod 5 = 1$, so 2 is the inverse of 3 modulo 5.

However, for $m = 6$, $\mathbb{Z}/6\mathbb{Z} = \{0 + 6\mathbb{Z}, 1+ 6\mathbb{Z}, 2+ 6\mathbb{Z}, 3+ 6\mathbb{Z}, 4+ 6\mathbb{Z}, 5+ 6\mathbb{Z}\}$ does not form a field because 6 is not prime, and not all elements have inverses. For instance, there is no inverse for 2, as $\gcd(2, 6) \neq 1$.

\begin{definition}{Primitive Residue Class Group}{}
The group of all primitive residue classes modulo $m$ is called the primitive residue class group, denoted by $(\mathbb{Z}/m\mathbb{Z})^{\times}$.
\end{definition}

Example: For $m = 8$, the set of all primitive residue classes is $(\mathbb{Z}/8\mathbb{Z})^{\times} = \{1 + 8\mathbb{Z}, 3 + 8\mathbb{Z}, 5 + 8\mathbb{Z}, 7 + 8\mathbb{Z}\}$. These are the integers less than 8 that are coprime to 8 (i.e., $\gcd(a, 8) = 1$).

Contrast this with $m = 9$. The primitive residue class group is $(\mathbb{Z}/9\mathbb{Z})^{\times} = \{1 + 9\mathbb{Z}, 2 + 9\mathbb{Z}, 4 + 9\mathbb{Z}, 5 + 9\mathbb{Z}, 7 + 9\mathbb{Z}, 8 + 9\mathbb{Z}\}$, as these are the integers less than 9 that are coprime to 9.


\begin{definition}{Euler's Totient Function}{}
Euler's totient function $\phi(m)$ is equal to the order of the primitive residue class group modulo $m$, which is the number of integers less than $m$ and coprime to $m$.
\end{definition}

Example: For $m = 12$, $\phi(12) = 4$ because there are 4 integers less than 12 that are coprime to 12: $\{1, 5, 7, 11\}$.

For $m = 10$, $\phi(10) = 4$, as there are also 4 integers less than 10 that are coprime to 10: $\{1, 3, 7, 9\}$.

\begin{definition}{Order of an element within a group}{}
    Order of $g \in G$ is the minimum number of natural number $e$ satisfying $g^{e} = 1$. We denote it as $\hbox{order}_g g$ or $\hbox{order } g$
\end{definition}

Example: In $(\mathbb{Z}/7\mathbb{Z})^{\times}$, the element 3 has order 6 because $3^6 \bmod 7 = 1$. In other words, $3 \times 3 \times 3 \times 3 \times 3 \times 3 \bmod 7 = 1$, and 6 is the smallest such exponent.

\begin{definition}{Subgroup}{}
    The subset $U \subseteq G$ is a subgroup of $G$ if $U$ itself is a group by the operation of $G$.
\end{definition}

Example: Consider $(\mathbb{Z}/8\mathbb{Z})^{\times} = \{1 + 8\mathbb{Z}, 3+ 8\mathbb{Z}, 5+ 8\mathbb{Z}, 7+ 8\mathbb{Z}\}$ under multiplication modulo 8. The subset $\{1+ 8\mathbb{Z}, 7+ 8\mathbb{Z}\}$ forms a subgroup because it satisfies the group properties: closed under multiplication, contains the identity element (1), and every element has an inverse ($7 \times 7 \equiv 1 \bmod 8$).

\begin{definition}{Subgroup generated by $g$}{} The set ${g^{k} : k \in \mathbb{Z}}$, for some element $g \in G$, forms a subgroup of $G$ and is called the subgroup generated by $g$, denoted by $\langle g \rangle$. \end{definition}

Example: Consider the group $(\mathbb{Z}/7\mathbb{Z})^{\times} = \{1+ 7\mathbb{Z}, 2+ 7\mathbb{Z}, 3+ 7\mathbb{Z}, 4+ 7\mathbb{Z}, 5+ 7\mathbb{Z}, 6+ 7\mathbb{Z}\}$ under multiplication modulo 7. If we take $g = 3$, then $\langle 3 +7\mathbb{Z} \rangle = \{3^1+7\mathbb{Z}, 3^2+7\mathbb{Z}, 3^3+7\mathbb{Z}, 3^4+7\mathbb{Z}, 3^5+7\mathbb{Z}, 3^6+7\mathbb{Z}\} \bmod 7 = \{3+7\mathbb{Z}, 2+7\mathbb{Z}, 6+7\mathbb{Z}, 4+7\mathbb{Z}, 5+7\mathbb{Z}, 1+7\mathbb{Z}\}$, which forms a subgroup generated by 3. This subgroup contains all elements of $(\mathbb{Z}/7\mathbb{Z})^{\times}$, making 3 a generator of the entire group.

If $g$ has a finite order $e$, we have that $\langle g \rangle = {g^{k}: 0 \leq k \leq e}$, meaning $e$ is the order of $\langle g \rangle$.

\begin{definition}{Cyclic Group}{} A group $G$ is called a cyclic group if there exists an element $g \in G$ such that $G = \langle g \rangle$. In this case, $g$ is called a generator of $G$. \end{definition}

Example: The group $(\mathbb{Z}/6\mathbb{Z})^{\times} = \{1+6\mathbb{Z}, 5+6\mathbb{Z}\}$ under multiplication modulo 6 is a cyclic group. In this case, both 1 and 5 are generators of the group because $\langle 5 +6\mathbb{Z} \rangle = \{(5^1 \bmod 6)+6\mathbb{Z} = 5 +6\mathbb{Z}, (5^2 \bmod 6)+6\mathbb{Z} = 1+6\mathbb{Z}\}$. Since 5 generates all the elements of the group, $G$ is cyclic.

\begin{theorem}{}{} If $G$ is a finite cyclic group, it has $\phi(|G|)$ generators, and each generator has order $|G|$. \end{theorem}

\begin{proof}
    TBD
\end{proof}

Example: Consider the group $(\mathbb{Z}/8\mathbb{Z})^{\times} = \{1+8\mathbb{Z}, 3+8\mathbb{Z}, 5+8\mathbb{Z}, 7+8\mathbb{Z}\}$. This group is cyclic, and $\phi(8) = 4$. The generators of this group are $\{1+8\mathbb{Z}, 3+8\mathbb{Z}, 5+8\mathbb{Z}, 7+8\mathbb{Z}\}$, each of which generates the entire group when raised to successive powers modulo 8. Each generator has the same order, which is $|G| = 4$.

\begin{theorem}{}{} If $G$ is a finite cyclic group, the order of any subgroup of $G$ divides the order of $G$. \end{theorem}

\begin{proof}
    TBD
\end{proof}

Example: Consider the cyclic group $(\mathbb{Z}/6\mathbb{Z})^{\times} = \{1+6\mathbb{Z}, 5+6\mathbb{Z}\}$ under multiplication modulo 6. If we take the subgroup $\langle 5+6\mathbb{Z} \rangle = \{1+6\mathbb{Z}, 5+6\mathbb{Z}\}$, this is a subgroup of order 2, and 2 divides the order of the original group, which is 6. This theorem generalizes this property: for any subgroup of a cyclic group, its order divides the order of the group.

\begin{theorem}{Fermat's Little Theorem}{} If $\gcd(a, m) = 1$, then $a^{\phi(m)} \equiv 1 \pmod{m}$. \end{theorem}

\begin{proof}
    TBD
\end{proof}

Example: Take $a = 2$ and $m = 5$. Since $\gcd(2, 5) = 1$, Fermat's Little Theorem tells us that $2^{\phi(5)} = 2^4 \equiv 1 \bmod 5$. Indeed, $2^4 = 16$ and $16 \bmod 5 = 1$.

This theorem suggests that $a^{\phi(m) - 1} + m \mathbb{Z}$ is the inverse residue class of $a + m \mathbb{Z}$.

\begin{theorem}{}{} The order of any element in a group divides the order of the group. \end{theorem}

\begin{proof}
    TBD
\end{proof}

Example: In the group $(\mathbb{Z}/7\mathbb{Z})^{\times}$, consider the element $3 + 7\mathbb{Z}$. The order of $3 + 7\mathbb{Z}$ is 6, as $3^6 \equiv 1 \bmod 7$. The order of the group itself is also 6, and indeed, the order of the element divides the order of the group.

\begin{theorem}{Generalization of Fermat's Little Theorem}{} For any element $g \in G$, we have $g^{|G|} = 1$. \end{theorem}

\begin{proof}
    TBD
\end{proof}

Example: In the group $(\mathbb{Z}/7\mathbb{Z})^{\times}$, for any element $g$, such as $g = 3 + 7\mathbb{Z}$, we have $3^6 \equiv 1 \bmod 7$. This holds for any $g \in (\mathbb{Z}/7\mathbb{Z})^{\times}$ because the order of the group is 6. Thus, $g^{|G|} = 1$ is satisfied.

\begin{definition}{Pairing}{}
Let $G_1$ and $G_2$ be cyclic groups under addition, both of prime order $p$, with generators $P$ and $Q$ respectively:

    \begin{align}
        G_1 &= \{0, P, 2P, ..., (p-1)P\} \\
        G_2 &= \{0, Q, 2Q, ..., (p-1)Q\}
    \end{align}

Let $G_T$ be a cyclic group under multiplication, also of order $p$.
A pairing is a map $e: G_1 \times G_2 \rightarrow G_T$ that satisfies the following bilinear property:

    \begin{equation}
        e(aP, bQ) = e(P, Q)^{ab}
    \end{equation} for all $a, b \in \mathbb{Z}_p$.
\end{definition}

Imagine $G_1$ represents length, $G_2$ represents width, and $G_T$ represents area. The pairing function $e$ is like calculating the area: If you double the length and triple the width, the area becomes six times larger: $e(2P, 3Q) = e(P, Q)^{6}$

\subsection{Polynomials}

\begin{definition}{Polynomial}{}
    A univariate polynomial over a commutative ring $R$ with unity $1$ is an expression of the form $f(x) = a_n x^{n} + a_{n-1} x^{n-1} + \cdots + a_1 x + a_0$, where $x$ is a variable and coefficients $a_0, \ldots, a_n$ belong to $R$. The set of all polynomials over $R$ in the variable $x$ is denoted as $R[x]$.
\end{definition}

Example: In $\mathbb{Z}[x]$, we have polynomials such as $2x^3 + x + 1$, $x$, and $1$. In $\mathbb{R}[x]$, we have polynomials like $\pi x^2 - \sqrt{2}x + e$.

\begin{definition}{Degree}{}
    The degree of a non-zero polynomial $f(x) = a_n x^{n} + a_{n-1} x^{n-1} + \cdots + a_1 x + a_0$, denoted as $\deg f$, is the largest integer $n$ such that $a_n \neq 0$. The zero polynomial is defined to have degree $-\infty$.
\end{definition}

Example: 

\begin{itemize}
    \item $\deg(2x^3 + x + 1) = 3$
    \item $\deg(x) = 1$
    \item $\deg(1) = 0$
    \item $\deg(0) = -\infty$
\end{itemize}


\begin{definition}{Sum of polynomials}{}
    For polynomials $f(x) = \sum_{i=0}^n a_i x^i$ and $g(x) = \sum_{i=0}^m b_i x^i$, their sum is defined as:
    $(f + g)(x) = \sum_{i=0}^{\max(n,m)} (a_i + b_i) x^i$
    where we set $a_i = 0$ for $i > n$ and $b_i = 0$ for $i > m$.
\end{definition}

Example: Let $f(x) = 2x^2 + 3x + 1$ and $g(x) = x^3 - x + 4$. Then, $(f + g)(x) = x^3 + 2x^2 + 2x + 5$

\begin{definition}{Product of polynomials}{}
    For polynomials $f(x) = \sum_{i=0}^n a_i x^i$ and $g(x) = \sum_{j=0}^m b_j x^j$, their product is defined as:
    $(fg)(x) = \sum_{k=0}^{n+m} c_k x^k$, where $c_k = \sum_{i+j=k} a_i b_j$
\end{definition}

Example: Let $f(x) = x + 1$ and $g(x) = x^2 - 1$. Then, $(fg)(x) = x^3 + x^2 - x - 1$

Let $K$ be a field.

\begin{lemma}{}{}
    Let $f, g \in K[x]$ be non-zero polynomials. Then, $\deg(fg) = \deg f + \deg g$.
\end{lemma}

Example: Let $f(x) = x^2 + 1$ and $g(x) = x^3 - x$ in $\mathbb{R}[x]$. Then, $\deg(fg) = \deg(x^5 - x^3 + x^2 + 1) = 5 = 2 + 3 = \deg f + \deg g$

We can also define division in the polynomial ring $K[x]$.

\begin{theorem}{}{}
    Let $f, g \in K[x]$, with $g \neq 0$. There exist unique polynomials $q, r \in K[x]$ that satisfy $f = qg + r$ and either $\deg r < \deg g$ or $r = 0$.
\end{theorem}

\begin{proof}
    TBD
\end{proof}

$q$ is called the quotient of $f$ divided by $g$, and $r$ is called the remainder; we write $r = f \bmod g$.

Example: In $\mathbb{R}[x]$, let $f(x) = x^3 + 2x^2 - x + 3$ and $g(x) = x^2 + 1$.  Then $f = qg + r$ where $q(x) = x + 2$ and $r(x) = -3x + 1$.

\begin{corollary}{}{}
    Let $f \in K[x]$ be a non-zero polynomial, and $a \in K$ such that $f(a) = 0$. Then, there exists a polynomial $q \in K[x]$ such that $f(x) = (x - a)q(x)$. In other words, $(x - a)$ is a factor of $f(x)$.
\end{corollary}


Example: Let $f(x) = x^2 + 1 \in (\mathbb{Z}/2\mathbb{Z})[x]$. We have $f(1) = 1^2 + 1 = 0$ in $\mathbb{Z}/2\mathbb{Z}$, and indeed: $x^2 + 1 = (x - 1)^2 = x^2 - 2x + 1 = x^2 + 1$ in $(\mathbb{Z}/2\mathbb{Z})[x]$

\begin{theorem}{Lagrange Interpolation}{}
    A $n$-degre polynomial $P(x)$ that goes through different $n + 1$ points $\{(x_1, y_1), (x_2, y_2), \cdots (x_{n + 1}, y_{n + 1})\}$ is uniquely represented as follows:

    \begin{equation}
        P(x) = \sum^{n+1}_{i=1} y_i \frac{f_i(x)}{f_i(x_i)}
    \end{equation}, where $f_i(x) = \prod_{k \neq i} (x - x_k)$
\end{theorem}

\begin{proof}
    TBD
\end{proof}

For example, the quadratic polynomial that goes through $\{(1, 0), (2, 3), (3, 8)\}$ is as follows:

\begin{equation*}
    P(x) = 0 \frac{(x - 2)(x - 3)}{(1 - 2) (1 - 3)} + 3 \frac{(x - 1)(x - 3)}{(2 - 1) (2 - 3)} + 8 \frac{(x - 1)(x - 2)}{(3 - 1) (3 - 2)} = x^{2} - 1
\end{equation*}

Note that Lagrange interpolation finds the lowest degree of interpolating polynomial for the given vector.

\begin{proposition}{Homomorphisms of Lagrange Interpolation}{}
Let $L(v)$ and $L(w)$ be the polynomial resulting from Lagrange Interpolation on the output ($y$) vector $v$ and $w$ for the same inputs ($x$). Then, the following properties hold:

\begin{itemize}
    \item Additivity: $L(v + w) = L(v) + L(w)$ for any vectors $v$ and $w$
    \item Scalar multiplication: $L(\gamma v) = \gamma L(v)$ for any scalar $\gamma$ and vector $v$
\end{itemize}
\end{proposition}

\begin{proof}
    
Let $v = (v_1, \ldots, v_n)$ and $w = (w_1, \ldots, w_n)$ be vectors, and $x_1, \ldots, x_n$ be the interpolation points.

\begin{align*}
    L(v + w) &= \sum_{i=1}^n (v_i + w_i) \prod_{j \neq i} \frac{x - x_j}{x_i - x_j} = \sum_{i=1}^n v_i \prod_{j \neq i} \frac{x - x_j}{x_i - x_j} + \sum_{i=1}^n w_i \prod_{j \neq i} \frac{x - x_j}{x_i - x_j} = L(v) + L(w) \\
    L(\gamma v) &= \sum_{i=1}^n (\gamma v_i) \prod_{j \neq i} \frac{x - x_j}{x_i - x_j} = \gamma \sum_{i=1}^n v_i \prod_{j \neq i} \frac{x - x_j}{x_i - x_j} = \gamma L(v)
\end{align*}
\end{proof}

\subsection{Finite Field}

We will now discuss the construction of finite fields with $p^n$ elements, where $p$ is a prime number and $n$ is a positive integer. These fields are also known as Galois fields, denoted as $GF(p^n)$. It is evident that $\mathbb{Z}/p\mathbb{Z}$ is isomorphic to $GF(p)$.


\begin{definition}{Irreducible Polynomial}{}
A polynomial $f \in (\mathbb{Z}/p\mathbb{Z})[X]$ of degree $n$ is called irreducible over $\mathbb{Z}/p\mathbb{Z}$ if it cannot be factored as a product of two polynomials of lower degree in $(\mathbb{Z}/p\mathbb{Z})[X]$.
\end{definition}

Example: In $(\mathbb{Z}/2\mathbb{Z})[X]$:
\begin{itemize}
    \item $X^2 + X + 1$ is irreducible
    \item $X^2 + 1 = (X + 1)^2$ is reducible
\end{itemize}

To construct $GF(p^n)$, we use an irreducible polynomial of degree $n$ over $\mathbb{Z}/p\mathbb{Z}$.

\begin{definition}{Residue Class modulo a Polynomial}{}
For $f, g \in (\mathbb{Z}/p\mathbb{Z})[X]$, the residue class of $g \bmod f$ is the set of all polynomials $h \in (\mathbb{Z}/p\mathbb{Z})[X]$ such that $h \equiv g \pmod{f}$. This class is denoted as:
\[ g + f(\mathbb{Z}/p\mathbb{Z})[X] = \{g + hf : h \in (\mathbb{Z}/p\mathbb{Z})[X]\} \]
\end{definition}

In $(\mathbb{Z}/2\mathbb{Z})[X]$, with $f(X) = X^2 + X + 1$, the residue classes $\bmod f$ are:
\begin{itemize}
    \item $0 + f(\mathbb{Z}/2\mathbb{Z})[X] = \{0, X^2 + X + 1, X^2 + X, X^2 + 1, X^2, X + 1, X, 1\}$
    \item $1 + f(\mathbb{Z}/2\mathbb{Z})[X] = \{1, X^2 + X, X^2 + 1, X^2, X + 1, X, 0, X^2 + X + 1\}$
    \item $X + f(\mathbb{Z}/2\mathbb{Z})[X] = \{X, X^2 + 1, X^2, X^2 + X + 1, X + 1, 1, X^2 + X, 0\}$
    \item $(X + 1) + f(\mathbb{Z}/2\mathbb{Z})[X] = \{X + 1, X^2, X^2 + X + 1, X^2 + X, 1, 0, X^2 + 1, X\}$
\end{itemize}
These four residue classes form $GF(4)$.

\begin{theorem}{}{}
If $f \in (\mathbb{Z}/p\mathbb{Z})[X]$ is an irreducible polynomial of degree $n$, then the residue ring $(\mathbb{Z}/p\mathbb{Z})[X]/(f)$ is a field with $p^n$ elements, isomorphic to $GF(p^n)$.
\end{theorem}

\begin{proof}
(Outline) The irreducibility of $f$ ensures that $(f)$ is a maximal ideal in $(\mathbb{Z}/p\mathbb{Z})[X]$, making the quotient ring a field. The number of elements is $p^n$ because there are $p^n$ polynomials of degree less than $n$ over $\mathbb{Z}/p\mathbb{Z}$.
\end{proof}

This construction allows us to represent elements of $GF(p^n)$ as polynomials of degree less than $n$ over $\mathbb{Z}/p\mathbb{Z}$. Addition is performed coefficient-wise modulo $p$, while multiplication is performed modulo the irreducible polynomial $f$.


Example: To construct $GF(8)$, we can use the irreducible polynomial $f(X) = X^3 + X + 1$ over $\mathbb{Z}/2\mathbb{Z}$. The elements of $GF(8)$ are represented by:
\[ \{0, 1, X, X+1, X^2, X^2+1, X^2+X, X^2+X+1\} \]
For instance, multiplication in $GF(8)$:
\[ (X^2 + 1)(X + 1) = X^3 + X^2 + X + 1 \equiv X^2 \pmod{X^3 + X + 1} \]

\begin{lemma}{Schwartz - Zippel Lemma}{}
Let $\mathbb{F}$ be a field and $P: F^m \rightarrow \mathbb{F}$ and $Q: \mathbb{F}^m \rightarrow \mathbb{F}$ be two distinct multivariate polynomials of total degree at most $n$. For any finite subset $\mathbb{S} \subseteq \mathbb{F}$, we have:
        \begin{equation}
            Pr_{u \sim \mathbb{S}^{m}}[P(u) = Q(u)] \leq \frac{n}{|\mathbb{S}|}
        \end{equation}
where $u$ is drawn uniformly at random from $\mathbb{S}^m$.
\end{lemma}

\begin{proof}
    TBD
\end{proof}

This lemma states that if $\mathbb{S}$ is sufficiently large and $n$ is relatively small, the probability that the two different polynomials return the same value for a randomly chosen input is negligibly small. In other words, if we observe $P(u) = Q(u)$ for a random input $u$, we can conclude with high probability that $P$ and $Q$ are identical polynomials.

\subsection{Elliptic curve}

\subsection{Assumptions}

\begin{assumption}{Discrete Logarithm Problem}{} Let $G$ be a finite cyclic group of order $n$, with $\gamma$ as its generator and $1$ as the identity element. For any element $\alpha \in G$, there is currently no known efficient (polynomial-time) algorithm to compute the smallest non-negative integer $x$ such that $\alpha = \gamma^{x}$.
\end{assumption}

The Discrete Logarithm Problem can be thought of as a one-way function. It's easy to compute $g^{x}$ given $g$ and $x$, but it's computationally difficult to find $x$ given $g$ and $g^{x}$.

\begin{assumption}{Knowledge of Exponent Assumption}{}
Let $G$ be a cyclic group of prime order $q$ with generator $g \in G$. For any probabilistic polynomial-time algorithm $\mathcal{A}$ that outputs:

\begin{equation}
\mathcal{A}(g, g^x) = (h, h') \quad s.t. \quad h' = h^x
\end{equation}
, there exists an efficient extractor $\mathcal{E}$ such that:
\begin{equation}
\mathcal{E}(\mathcal{A}, g, g^x) = y \quad s.t. \quad h = g^y
\end{equation}
\end{assumption}

This assumption states that if $\mathcal{A}$ can compute the pair $(g^y, g^{xy})$ from $(g, g^x)$, then $\mathcal{A}$ must "know" the value $y$, in the sense that $\mathcal{E}$ can extract $y$ from $\mathcal{A}$'s internal state.
The Knowledge of Exponent Assumption is useful for constructing verifiable exponential calculation algorithms. Consider a scenario where Alice has a secret value $a$, and Bob has a secret value $b$. Bob wants to obtain $g^{ab}$. This can be achieved through the following protocol:

\begin{protocol}{Verifiable Exponential Calculation Algorithm}{}
    \begin{enumerate}
    \item Bob sends $(g, g'=g^{b})$ to Alice
    \item Alice sends $(h=g^{a}, h'=g'^{a})$ to Bob
    \item Bob checks $h^{b} = h'$.
\end{enumerate}
\end{protocol}

Thanks to the Discrete Logarithm Assumption and the Knowledge of Exponent Assumption, the following properties hold:
\begin{itemize}
\item Alice cannot derive $b$ from $(g, g')$.
\item Bob cannot derive $a$ from $(h, h')$.
\item Alice knows a value $a$ such that $h = g^a$. In other words, $h$ is the power of $g$.
\end{itemize}

\subsection{Useful Algorithms}

\paragraph{Euclidean Algorithm}

\paragraph{Generation of Primes}

\paragraph{Fast Fourier Transform}

\section{Basic of zk-SNARKs}

Based on~\cite{petkus2019and}, we will explore the design of zk-SNARKs by incrementally developing zero-knowledge proof protocols.

\paragraph{Overview}

\subsection{Arithmetization}

The ultimate goal of Zero-Knowledge Proofs (ZKP) is to allow the prover to demonstrate their knowledge to the verifier without revealing any additional information. This knowledge typically involves solving complex problems, such as finding a secret input value that corresponds to a given public hash. ZKP protocols usually convert these statements into polynomial constraints. This process is often called \textit{arithmetization}.

To make the protocol flexible, we need to encode this knowledge in a specific format, and one common approach is using Boolean circuits. It's well-known that problems in P (those solvable in polynomial time) and NP (those where the solution can be verified in polynomial time) can be represented as Boolean circuits. This means adopting Boolean circuits allows us to handle both P and NP problems.

However, Boolean circuits are often large and inefficient. Even a simple operation, like adding two 256-bit integers, can require hundreds of Boolean operators. In contrast, arithmetic circuits—essentially systems of equations involving addition, multiplication, and equality—offer a much more compact representation. Additionally, any Boolean circuit can be converted into an arithmetic circuit. For instance, the Boolean expression $z = x \land y$ can be represented as $x(x-1) = 0$, $y(y-1) = 0$, and $z = xy$ in an arithmetic circuit. Furthermore, as we'll see in this section, converting arithmetic circuits into polynomial constraints allows for much faster evaluation.

\subsubsection{Rank-1 Constraint System (R1CS)}

There are many formats to represent arithmetic circuits, and one of the most popular ones is R1CS (Rank-1 Constraint System), which represents arithmetic circuits as \underline{a set of equality constraints, each involving only one multiplication}. In an arithmetic circuit, we call the concrete values assigned to the variables within the constraints witness. We first provide the formal definition of R1CS as follows:

\begin{definition}{R1CS}{}

An R1CS structure $\mathcal{S}$ consists of:
\begin{itemize}
\item Size bounds $m, d, \ell \in \mathbb{N}$ where $d > \ell$
\item Three matrices $O, L, R \in \mathbb{F}^{m\times d}$ with at most $ \Omega(\max(m, d))$ non-zero entries in total
\end{itemize}

An R1CS instance includes a public input $p \in \mathbb{F}^\ell$, while an R1CS witness is a vector $w \in \mathbb{F}^{d - \ell - 1}$.
A structure-instance tuple $(S, p)$ is satisfied by a witness $w$ if:
\begin{equation}
(L \cdot a) \circ (R \cdot a) - O \cdot a = \mathbf{0}
\end{equation}
where $a = (1, w, p) \in \mathbb{F}^d$, $\cdot$ denotes matrix-vector multiplication, and $\circ$ is the Hadamard product.

\end{definition}

The intuitive interpretation of each matrix is as follows:

\begin{itemize}
\item $L$: Encodes the left input of each gate
\item $R$: Encodes the right input of each gate
\item $O$: Encodes the output of each gate
\item The leading 1 in the witness vector allows for constant terms
\end{itemize}

\paragraph{Single Multiplication}

Let's consider a simple example where we want to prove $z = x \cdot y$, with $z = 3690$, $x = 82$, and $y = 45$.

\begin{itemize}
    \item \textbf{Witness vector}: $(1, z, x, y) = (1, 3690, 82, 45)$
    \item \textbf{Number of witnesses}: $m = 4$
    \item \textbf{Number of constraints}: $d = 1$
\end{itemize}

The R1CS constraint for $z = x \cdot y$ is satisfied when:

\begin{align*}
&(\begin{bmatrix} 0 & 0 & 1 & 0 \end{bmatrix} \cdot a) \circ (\begin{bmatrix} 0 & 0 & 0 & 1 \end{bmatrix} \cdot a) - \begin{bmatrix} 0 & 1 & 0 & 0 \end{bmatrix} \cdot a \\
=&(\begin{bmatrix} 0 & 0 & 1 & 0 \end{bmatrix} \cdot \begin{bmatrix}
1 \\ 3690 \\ 82 \\ 45
\end{bmatrix}) \circ (\begin{bmatrix} 0 & 0 & 0 & 1 \end{bmatrix} \cdot \begin{bmatrix}
1 \\ 3690 \\ 82 \\ 45
\end{bmatrix}) - \begin{bmatrix} 0 & 1 & 0 & 0 \end{bmatrix} \cdot \begin{bmatrix}
1 \\ 3690 \\ 82 \\ 45
\end{bmatrix} \\
=& 82 \cdot 45 - 3690 \\
=& 3690 - 3690 \\
=& 0
\end{align*}

This example demonstrates how R1CS encodes a simple multiplication constraint:
\begin{itemize}
\item $L = \begin{bmatrix} 0 & 0 & 1 & 0 \end{bmatrix}$ selects $x$ (left input)
\item $R = \begin{bmatrix} 0 & 0 & 0 & 1 \end{bmatrix}$ selects $y$ (right input)
\item $O = \begin{bmatrix} 0 & 1 & 0 & 0 \end{bmatrix}$ selects $z$ (output)
\end{itemize}

\paragraph{Multiple Constraints}

Let's examine a more complex example: $r = a \cdot b \cdot c \cdot d$. Since R1CS requires that each constraint contain only one multiplication, we need to break this down into multiple constraints:

\begin{align*}
v_1 &= a \cdot b \\
v_2 &= c \cdot d \\
r &= v_1 \cdot v_2
\end{align*}

Note that alternative representations are possible, such as $v_1 = ab, v_2 = v_1c, r = v_2d$. In this example, we use 7 variables $(r, a, b, c, d, v_1, v_2)$, so the dimension of the witness vector will be $m = 8$ (including the constant 1). We have three constraints, so $n = 3$.
To construct the matrices $L$, $R$, and $O$, we can interpret the constraints as linear combinations:

\begin{align*}
v_1 &= (0 \cdot 1 + 0 \cdot r + 1 \cdot a + 0 \cdot b + 0 \cdot c + 0 \cdot d + 0 \cdot v_1 + 0 \cdot v_2) \cdot b \\
v_2 &= (0 \cdot 1 + 0 \cdot r + 0 \cdot a + 0 \cdot b + 1 \cdot c + 0 \cdot d + 0 \cdot v_1 + 0 \cdot v_2) \cdot d \\
r &= (0 \cdot 1 + 0 \cdot r + 0 \cdot a + 0 \cdot b + 0 \cdot c + 0 \cdot d + 1 \cdot v_1 + 0 \cdot v_2) \cdot v_2
\end{align*}

Thus, we can construct $L$, $R$, and $O$ as follows:

\begin{equation*}
L = \begin{bmatrix}
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0
\end{bmatrix}
\end{equation*}
\begin{equation*}
R = \begin{bmatrix}
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}
\end{equation*}
\begin{equation*}
O = \begin{bmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0
\end{bmatrix}
\end{equation*}

Where the columns in each matrix correspond to $(1, r, a, b, c, d, v_1, v_2)$.

\paragraph{Addition with a Constant}

Let's examine the case $z = x \cdot y + 3$. We can represent this as $-3 + z = x \cdot y$. For the witness vector $(1, z, x, y)$, we have:

\begin{align*}
L &= \begin{bmatrix}
0 & 0 & 1 & 0
\end{bmatrix} \\
R &= \begin{bmatrix}
0 & 0 & 0 & 1
\end{bmatrix} \\
O &= \begin{bmatrix}
-3 & 1 & 0 & 0
\end{bmatrix}
\end{align*}

Note that the constant 3 appears in the $O$ matrix with a negative sign, effectively moving it to the left side of the equation

\paragraph{Multiplication with a Constant}

Now, let's consider $z = 3x^2 + y$. The requirement of "one multiplication per constraint" doesn't apply to multiplication with a constant, as we can treat it as repeated addition.

\begin{align*}
L &= \begin{bmatrix}
0 & 0 & 3 & 0
\end{bmatrix} \\
R &= \begin{bmatrix}
0 & 0 & 1 & 0
\end{bmatrix} \\
O &= \begin{bmatrix}
0 & 1 & 0 & -1
\end{bmatrix}
\end{align*}

\subsubsection{Quadratic Arithmetic Program (QAP)}
Recall that the prover aims to demonstrate knowledge of a witness $w$ without revealing it. This is equivalent to knowing a vector $a$ that satisfies $(L \cdot a) \circ (R \cdot a) = O \cdot a$, where $\circ$ denotes the Hadamard (element-wise) product. However, evaluating this equivalence directly requires $\Omega(d)$ operations, where $d$ is the number of rows. To improve efficiency, we can convert this matrix comparison to a polynomial comparison, leveraging the Schwartz-Zippel Lemma, which allows us to check polynomial equality with $\Omega(1)$ evaluations.

Let's consider a simpler example to illustrate this concept. Suppose we want to test the equivalence $Av = Bu$, where:

\begin{align*}
A = \begin{bmatrix}
2 & 5 \\
3 & 1 \\
\end{bmatrix},
B = \begin{bmatrix}
4 & 1 \\
2 & 3 \\
\end{bmatrix},
v = \begin{bmatrix}
3 \\ 1
\end{bmatrix},
u = \begin{bmatrix}
2 \\ 2
\end{bmatrix}
\end{align*}
The equivalence check can be represented as:
\begin{equation*}
\begin{bmatrix}
2 \\ 3
\end{bmatrix} \cdot 3 + \begin{bmatrix}
5 \\ 1
\end{bmatrix} \cdot 1 = \begin{bmatrix}
4 \\ 2
\end{bmatrix} \cdot 2 + \begin{bmatrix}
1 \\ 3
\end{bmatrix} \cdot 2
\end{equation*}
This matrix-vector equality check is equivalent to the following polynomial equality check:
\begin{equation*}
3 \cdot L([(1, 2), (2, 3)]) + 1 \cdot L([(1, 5), (2, 1)]) = 2 \cdot L([(1, 4), (2, 2)]) + 2 \cdot L([(1, 1), (2, 3)])
\end{equation*}
where $L$ denotes Lagrange Interpolation. In $\mathbb{F}_{11}$ (field with 11 elements), we have:
\begin{align*}
L([(1, 2), (2, 3)]) &= x + 1 \\
L([(1, 5), (2, 1)]) &= 7x + 9 \\
L([(1, 4), (2, 2)]) &= 9x + 6 \\
L([(1, 1), (2, 3)]) &= 2x + 10
\end{align*}
The Schwartz-Zippel Lemma states that we need only one evaluation at a random point to check the equivalence of polynomials with high probability.
However, the homomorphic property for multiplication doesn't hold for Lagrange Interpolation. Thus, we don't have $\ell(x) \cdot r(x) = o(x)$, where $\ell(x)$, $r(x)$, and $o(x)$ are the polynomials resulting from the Lagrange interpolation of $L \cdot a$, $R \cdot a$, and $O \cdot a$ respectively. While $\ell(x)$, $r(x)$, and $o(x)$ are of degree at most $d-1$, $\ell(x) \cdot r(x)$ is of degree at most $2d-2$.
To address this discrepancy, we introduce a degree $d$ polynomial $t(x) = \prod_{i=1}^{d} (x - i)$. We can then rewrite the equation as:
\begin{equation}
\ell(x) \cdot r(x) = o(x) + h(x) \cdot t(x)
\end{equation}
where $h(x) = \frac{\ell(x) \cdot r(x) - o(x)}{t(x)}$. This formulation allows us to maintain the desired polynomial relationships while accounting for the degree differences.

\subsection{Polynomial Commitment}

Before dealing with all of $\ell(x)$, $r(x)$, and $o(x)$ at once, we design a protocol that allows the Prover $\mathcal{A}$ to convince the Verifier $\mathcal{B}$ that $\mathcal{A}$ knows a specific polynomial. Let's denote this polynomial of degree $n$ with coefficients in a finite field as:

\begin{equation}
    P(x) = c_0 + c_1 x + c_2 x^{2} + \cdots c_n x^{n}
\end{equation}

Assume $P(x)$ has $n$ roots, $a_1, a_2, \ldots, a_n \in \mathbb{F}$, such that $P(x) = (x - a_1)(x - a_2)\cdots(x - a_n)$. The Verifier $\mathcal{B}$ knows $d < n$ roots of $P(x)$, namely $a_1, a_2, \ldots, a_d$. Let $T(x) = (x - a_1)(x - a_2)\cdots(x - a_d)$. Note that the Prover also knows $T(x)$.

The Prover's objective is to convince the Verifier that $\mathcal{A}$ knows a polynomial $H(x) = \frac{P(x)}{T(x)}$.

\paragraph{Naive Approach}

The simplest approach to prove that $\mathcal{A}$ knows $H(x)$ is as follows:

\begin{protocol}{Naive Approach}{}
\begin{enumerate}
    \item $\mathcal{B}$ sends all possible values in $\mathbb{F}$ to $\mathcal{A}$.
    \item $\mathcal{A}$ computes and sends all possible outputs of $H(x)$ and $P(x)$.
    \item $\mathcal{B}$ checks whether $H(a)T(a) = P(a)$ holds for any $a$ in $\mathbb{F}$.
\end{enumerate}
\end{protocol}

This protocol is highly inefficient, requiring $\mathcal{O}(|\mathbb{F}|)$ evaluations and communications.

\paragraph{$+$ Schwartz-Zippel Lemma}

Instead of evaluating polynomials at all values in $\mathbb{F}$, we can leverage the Schwartz-Zippel Lemma: if $H(s) = \frac{P(s)}{T(s)}$ or equivalently $H(s)T(s) = P(s)$ for a random element $s$, we can conclude that $H(x) = \frac{P(x)}{T(x)}$ with high probability. Thus, the Prover $\mathcal{A}$ only needs to send evaluations of $P(s)$ and $H(s)$ for a random input $s$ received from $\mathcal{B}$

\begin{protocol}{$+$ Schwartz-Zippel Lemma}{}
    \begin{enumerate}
    \item $\mathcal{B}$ draws random $s$ from $\mathbb{F}$ and sends it to $\mathcal{A}$.
    \item $\mathcal{A}$ computes $h = H(s)$ and $p = P(s)$ and send them to $\mathcal{B}$.
    \item $\mathcal{B}$ checks whether $p = t h$, where $t$ denotes $T(s)$.
\end{enumerate}
\end{protocol}

This protocol is efficient, requiring only a constant number of evaluations and communications. However, it is vulnerable to a malicious prover who could send an arbitrary value $h'$ and the corresponding $p'$ such that $p' = h't$.

\paragraph{$+$ Discrete Logarithm Assumption}

To address this vulnerability, the Verifier must hide the randomly chosen input $s$ from the Prover. This can be achieved using the discrete logarithm assumption: it is computationally hard to determine $s$ from $\alpha$, where $\alpha = g^s \bmod p$. Thus, it's safe for the Verifier to send $\alpha$, as the Prover cannot easily derive $s$ from it.

An interesting property of polynomial exponentiation is:

\begin{align}
    g^{P(x)} &= g^{c_0 + c_1 x + c_2 x^{2} + \cdots c_n x^{n}} = g^{c_0} (g^{x})^{c_1}  (g^{x^2})^{c_2} \cdots (g^{x^n})^{c_n}
\end{align}

Instead of sending $s$, the Verifier can send $g$, $\alpha = g^s$, and its powers: $\alpha, \alpha^2, \ldots, \alpha^n$. The Prover can still evaluate $g^p = g^{P(s)}$ using these powers of $\alpha$:

\begin{equation}
    g^{p} = g^{P(s)} = g^{c_0} \alpha^{c_1} (\alpha^{2})^{c_2} \cdots (\alpha^{n})^{c_n}
\end{equation}

Similarly, the Prover can evaluate $g^h = g^{H(s)}$. The Verifier can then check $p = ht \iff g^p = (g^h)^t$.

\begin{protocol}{$+$ Discrete Logarithm Assumption}{}
\begin{enumerate}
    \item $\mathcal{B}$ randomly draw $s$ from $\mathbb{F}$.
    \item $\mathcal{B}$ computes and sends $\{\alpha, \alpha^2, ..., \alpha^{n}\}$, where $\alpha = g^{s}$.
    \item $\mathcal{A}$ computes and sends $u = g^{p}$ and $v = g^{h}$.
    \item $\mathcal{B}$ checks whether $u = v^{t}$.
\end{enumerate}
\end{protocol}

This approach prevents the Prover from obtaining $s$ or $t = T(s)$, making it impossible to send fake $(h', p')$ such that $p' = h't$.

However, this protocol still has a flaw. Since the Prover can compute $g^t = \alpha^{c_1}(\alpha^2)^{c_2}\cdots(\alpha^d)^{c_d}$, they could send fake values $((g^{t})^{z}, g^{z})$ instead of $(g^p, g^h)$ for an arbitrary value $z$. The verifier's check would still pass, and they could not detect this deception.

\paragraph{$+$ Knowledge of Exponent Assumption}

To address the vulnerability where the verifier $\mathcal{B}$ cannot distinguish if $v (= g^h)$ from the prover is a power of $\alpha = g^s$, we can employ the Knowledge of Exponent Assumption. This approach involves the following steps:

\begin{enumerate}
    \item $\mathcal{B}$ sends both $\alpha$ and $\alpha' = \alpha^r$ for a new random value $r$.
    \item The prover returns $a = (\alpha^i)^{c_i}$ and $a' = (\alpha'^i)^{c_i}$ for $i = 1, ..., n$.
    \item $\mathcal{B}$ can conclude that $a$ is a power of $\alpha$ if $a^r = a'$.
\end{enumerate}

Based on this assumption, we can design an improved protocol:

\begin{protocol}{$+$ Knowledge of Exponent Assumption}{}
\begin{enumerate}
    \item $\mathcal{B}$ randomly selects $s$ and $r$ from field $\mathbb{F}$.
    \item $\mathcal{B}$ computes and sends $\{\alpha, \alpha^2, ..., \alpha^{n}\}$ and $\{\alpha', \alpha'^2, ..., \alpha'^{n}\}$, where $\alpha = g^{s}$ and $\alpha' = \alpha^{r} = g^{sr}$.
    \item $\mathcal{A}$ computes and sends $u = g^{p}$, $v = g^{h}$, and $w = g^{p'}$, where $g^{p'} = g^{P(sr)}$.
    \item $\mathcal{B}$ checks whether $u^{r} = w$.
    \item $\mathcal{B}$ checks whether $u = v^{t}$.
\end{enumerate}
\end{protocol}

The prover can compute $g^{p'} = g^{P(sr)} = \alpha'^{c_1} (\alpha'^{2})^{c_2} \cdots (\alpha'^{n})^{c_n}$) using powers of $\alpha'$. This protocol now satisfies the properties of a SNARK: completeness, soundness, and efficiency.

\paragraph{$+$ Zero Knowledge}

To transform the above protocol into a zk-SNARK, we need to ensure that the verifier cannot learn anything about $P(x)$ from the prover's information. This is achieved by having the prover obfuscate all information with a random secret value $\delta$:

\begin{protocol}{$+$ Zero Knowledge}{}
\begin{enumerate}
    \item $\mathcal{B}$ randomly selects $s$ and $r$ from field $\mathbb{F}$.
    \item $\mathcal{B}$ computes and sends $\{\alpha, \alpha^2, ..., \alpha^{n}\}$ and $\{\alpha', \alpha'^2, ..., \alpha'^{n}\}$, where $\alpha = g^{s}$ and $\alpha' = \alpha^{r} = g^{sr}$.
    \item $\mathcal{A}$ randomly selects $\delta$ from field $\mathbb{F}$.
    \item $\mathcal{A}$ computes and sends $u' = (g^{p})^{\delta}$, $v' = (g^{h})^{\delta}$, and $w' = (g^{p'})^{\delta}$.
    \item $\mathcal{B}$ checks whether $u'^{r} = w'$.
    \item $\mathcal{B}$ checks whether $u' = v'^{t}$.
\end{enumerate}
\end{protocol}

By introducing the random value $\delta$, the verifier can no longer learn anything about $p$, $h$, or $w$, thus achieving zero knowledge.

\paragraph{$+$ Non-interactivity}

The previously described protocol requires each verifier to generate unique random values, which becomes inefficient when a prover needs to demonstrate knowledge to multiple verifiers. To address this, we aim to eliminate the interaction between the prover and verifier. One effective solution is the use of a trusted setup.

\begin{protocol}{$+$ Non-Interactive: Trusted Setup}{}
\begin{enumerate}
    \item \textbf{Secret Seed}: A trusted third party generates the random values $s$ and $r$
    \item \textbf{Proof Key}: Provided to the prover \begin{enumerate}
        \item $\{\alpha, \alpha^2, ..., \alpha^{n}\}$, where $\alpha = g^{s}$
        \item $\{\alpha', \alpha'^2, ..., \alpha'^{n}\}$, where $\alpha' = g^{sr}$
        \end{enumerate}
    \item \textbf{Verification Key}: Distributed to verifiers \begin{enumerate}
        \item $g^{r}$
        \item $g^{T(s)}$
    \end{enumerate}
    \item After distribution, the original $s$ and $r$ values are securely destroyed.
\end{enumerate}
\end{protocol}



Then, the non-interactive protocol consists of two main parts: proof generation and verification.

\begin{protocol}{$+$ Non-Interactive: Proof}{}
    \begin{enumerate}
        \item $\mathcal{A}$ receives the proof key
        \item $\mathcal{A}$ randomly selects $\delta$ from field $\mathbb{F}$.
        \item $\mathcal{A}$ broadcast the proof $\pi = (u' = (g^{p})^{\delta}, v' = (g^{h})^{\delta}, w' = (g^{p'})^{\delta})$
    \end{enumerate}
\end{protocol}

Since $r$ is not shared and already destroyed, the verifier $\mathcal{B}$ cannot calculate $u'^{r}$ to check $u'^{r} = w'$. Instead, the verifier can use a paring with bilinear mapping; $u'^{r} = w'$ is equivalent to $e(u' = (g^{p})^{\delta}, g^{r}) = e(w'=(g^{p'})^{\delta}, g)$.

\begin{protocol}{$+$ Non-Interactive: Verification}{}
    \begin{enumerate}
        \item $\mathcal{B}$ receives the verification key.
        \item $\mathcal{B}$ receives the proof $\pi$.
        \item $\mathcal{B}$ checks whether $e(u', g^{r}) = e(w', g)$.
        \item $\mathcal{B}$ checks whether $u' = v'^{t}$.
    \end{enumerate}
\end{protocol}

\subsection{Putting it all together}

\subsection{(Advanced) Rigorous Design of Groth16}

\subsection{Circom: Domestic Specific Language for zk-SNARKs}

\section{Basic of zk-STARKs}


%Bibliography
\bibliographystyle{unsrt}  
\bibliography{references}  
%\end{multicols}


\appendix


\end{document}
